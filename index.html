<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Teaching Large Language Models to Think Twice - Research Paper</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 16px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 15px;
            font-weight: 700;
        }

        .header p {
            font-size: 1.2em;
            opacity: 0.95;
            margin-bottom: 10px;
        }

        .authors {
            font-size: 1.1em;
            margin-top: 20px;
            font-weight: 500;
        }

        .content {
            padding: 40px;
        }

        .section {
            margin-bottom: 30px;
        }

        .section h2 {
            color: #667eea;
            font-size: 1.8em;
            margin-bottom: 15px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }

        .section p {
            font-size: 1.1em;
            line-height: 1.8;
            color: #555;
            margin-bottom: 15px;
        }

        .highlights {
            background: #f8f9ff;
            border-left: 4px solid #667eea;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
        }

        .highlights h3 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .highlights ul {
            list-style: none;
            padding-left: 0;
        }

        .highlights li {
            padding: 8px 0;
            padding-left: 25px;
            position: relative;
            font-size: 1.05em;
        }

        .highlights li:before {
            content: "‚úì";
            position: absolute;
            left: 0;
            color: #667eea;
            font-weight: bold;
            font-size: 1.2em;
        }

        .buttons {
            display: flex;
            gap: 20px;
            margin: 30px 0;
            flex-wrap: wrap;
            justify-content: center;
        }

        .btn {
            display: inline-block;
            padding: 15px 35px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            text-decoration: none;
            border-radius: 8px;
            font-weight: 600;
            font-size: 1.1em;
            transition: transform 0.3s, box-shadow 0.3s;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }

        .btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 25px rgba(102, 126, 234, 0.6);
        }

        .btn-secondary {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            box-shadow: 0 4px 15px rgba(245, 87, 108, 0.4);
        }

        .btn-secondary:hover {
            box-shadow: 0 8px 25px rgba(245, 87, 108, 0.6);
        }

        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }

        .stat-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 12px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
        }

        .stat-card h3 {
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 700;
        }

        .stat-card p {
            font-size: 1em;
            opacity: 0.95;
            color: white;
        }

        .footer {
            background: #f8f9ff;
            padding: 30px;
            text-align: center;
            color: #666;
            font-size: 0.95em;
        }

        .footer a {
            color: #667eea;
            text-decoration: none;
            font-weight: 600;
        }

        .footer a:hover {
            text-decoration: underline;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8em;
            }

            .buttons {
                flex-direction: column;
            }

            .btn {
                width: 100%;
            }

            .stats {
                grid-template-columns: 1fr;
            }
        }

        .pdf-embed {
            width: 100%;
            height: 800px;
            border: none;
            border-radius: 8px;
            margin: 20px 0;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Teaching Large Language Models to Think Twice</h1>
            <p>A Three-Stage Framework for Self-Correcting Mathematical Reasoning</p>
            <div class="authors">
                <p><strong>Md Anisur Rahman Chowdhury*, Pratham Patel*, Shahajada Jawar, Kefei Wang</strong></p>
                <p style="font-size: 0.9em; opacity: 0.9;">Department of Computer and Information Science<br>
                   Gannon University, USA</p>
            </div>
        </div>

        <div class="content">
            <div class="section">
                <h2>üìÑ Read the Paper</h2>
                <div class="buttons">
                    <a href="ieee_conference_final.pdf" class="btn" target="_blank">
                        üìñ View PDF in Browser
                    </a>
                    <a href="ieee_conference_final.pdf" class="btn btn-secondary" download>
                        ‚¨áÔ∏è Download PDF
                    </a>
                    <a href="https://github.com/ANIS151993/Self-Correcting-LLM-localhost" class="btn">
                        üíª View on GitHub
                    </a>
                </div>
            </div>

            <div class="section">
                <h2>üéØ Key Results</h2>
                <div class="stats">
                    <div class="stat-card">
                        <h3>49.9%</h3>
                        <p>Accuracy on GSM8K</p>
                    </div>
                    <div class="stat-card">
                        <h3>60%</h3>
                        <p>Relative Improvement</p>
                    </div>
                    <div class="stat-card">
                        <h3>78%</h3>
                        <p>Error Correction Rate</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üî¨ Abstract</h2>
                <p>
                    Modern large language models struggle with complex mathematical reasoning tasks despite their
                    impressive performance across various natural language processing applications. The primary
                    challenge lies in their inability to detect and correct errors during multi-step problem-solving,
                    where early mistakes cascade through subsequent reasoning steps.
                </p>
                <p>
                    This paper presents a practical framework enabling language models to systematically verify and
                    refine their solutions through structured self-correction. Our approach organizes the problem-solving
                    process into three distinct stages: generating initial solutions with explicit identification of
                    critical reasoning steps, analyzing these solutions for potential errors, and producing corrected
                    final answers.
                </p>
            </div>

            <div class="highlights">
                <h3>‚ú® Key Contributions</h3>
                <ul>
                    <li>Three-stage self-correction framework (Generator ‚Üí Critic ‚Üí Synthesizer)</li>
                    <li>Novel three-phase training methodology combining supervised learning with reinforcement techniques</li>
                    <li>Comprehensive experimental validation on GSM8K mathematical reasoning benchmark</li>
                    <li>60% relative improvement in accuracy (from 31.2% to 49.9%)</li>
                    <li>Detailed error analysis revealing 78% correction success rate on computational errors</li>
                    <li>Superior computational efficiency compared to ensemble methods</li>
                </ul>
            </div>

            <div class="section">
                <h2>üìä Methodology</h2>
                <p>
                    Our framework decomposes mathematical problem-solving into three sequential stages:
                </p>
                <ul style="padding-left: 20px; margin-top: 15px;">
                    <li style="margin-bottom: 10px;"><strong>Stage 1 - Generator:</strong> Produces initial solutions
                        with explicit critical point identification</li>
                    <li style="margin-bottom: 10px;"><strong>Stage 2 - Critic:</strong> Systematically analyzes solutions
                        for potential errors and logical inconsistencies</li>
                    <li style="margin-bottom: 10px;"><strong>Stage 3 - Synthesizer:</strong> Produces refined solutions
                        addressing identified issues</li>
                </ul>
            </div>

            <div class="section">
                <h2>üìà Performance Highlights</h2>
                <div class="highlights">
                    <ul>
                        <li>49.9% accuracy on GSM8K benchmark (baseline: 31.2%)</li>
                        <li>Statistical significance: p < 0.001, McNemar's œá¬≤ = 287.4</li>
                        <li>Large effect size: Cohen's d = 0.94</li>
                        <li>Only 1.6√ó computational overhead vs single-pass generation</li>
                        <li>84% fewer tokens than self-consistency methods</li>
                        <li>5.6% new error introduction rate (very low)</li>
                    </ul>
                </div>
            </div>

            <div class="section">
                <h2>üìß Contact</h2>
                <p>
                    <strong>Corresponding Authors:</strong><br>
                    Md Anisur Rahman Chowdhury - <a href="mailto:engr.aanis@gmail.com">engr.aanis@gmail.com</a><br>
                    Pratham Patel - <a href="mailto:patel292@gannon.edu">patel292@gannon.edu</a>
                </p>
                <p>
                    <strong>Co-Authors:</strong><br>
                    Shahajada Jawar - <a href="mailto:shahajadajawar@gmail.com">shahajadajawar@gmail.com</a><br>
                    Kefei Wang - <a href="mailto:wang039@gannon.edu">wang039@gannon.edu</a>
                </p>
            </div>
        </div>

        <div class="footer">
            <p>
                ¬© 2025 Md Anisur Rahman Chowdhury, Pratham Patel, Shahajada Jawar, Kefei Wang |
                Gannon University |
                <a href="https://github.com/ANIS151993/Self-Correcting-LLM-localhost">GitHub Repository</a>
            </p>
        </div>
    </div>
</body>
</html>
